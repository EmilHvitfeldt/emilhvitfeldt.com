---
title: Tidy Text Summarization using TextRank
date: '2018-03-15'
categories: [tidytext]
---



<p><em>This code have been lightly revised to make sure it works as of 2018-12-19.</em></p>
<div id="text-summarization" class="section level2">
<h2>Text summarization</h2>
<p>In the realm of text summarization there two main paths:</p>
<ul>
<li>extractive summarization</li>
<li>abstractive summarization</li>
</ul>
<p>Where extractive scoring word and sentences according to some metric and then using that information to summarize the text. Usually done by copy/pasting (extracting) the most informative parts of the text.</p>
<p>The abstractive methods aims to build a semantic representation of the text and then use natural language generation techniques to generate text describing the informative parts.</p>
<p>Extractive summarization is primarily the simpler task, with a handful of algorithms do will do the scoring. While with the advent of deep learning did NLP have a boost in abstractive summarization methods.</p>
<p>In this post will I focus on an example of a extractive summarization method called <a href="https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf">TextRank</a> which is based on the <a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a> algorithm that is used by Google to rank websites by their importance.</p>
</div>
<div id="textrank-algorithm" class="section level2">
<h2>TextRank Algorithm</h2>
<p>The TextRank algorithm is based on graph-based ranking algorithm. Generally used in web searches at Google, but have many other applications. Graph-based ranking algorithms try to decide the importance of a vertex by taking into account information about the entire graph rather then the vertex specific information. A typical piece of information would be information between relationships (edges) between the vertices.</p>
<p>In the NLP case we need to define the what we want to use as vertices and edges. In our case will we be using sentences as the vertices and words as the connection edges. So sentences with words that appear in many other sentences are seen as more important.</p>
</div>
<div id="data-preparation" class="section level2">
<h2>Data preparation</h2>
<p>We start by loading the appropriate packages, which include <code>tidyverse</code> for general tasks, <code>tidytext</code> for text manipulations, <code>textrank</code> for the implementation of the TextRank algorithm and finally <code>rvest</code> to scrape an article to use as an example. The github for the <code>textrank</code> package can be found <a href="https://github.com/bnosac/textrank">here</a>.</p>
<pre class="r"><code>library(tidyverse)
## Warning: package &#39;tibble&#39; was built under R version 3.6.2
library(tidytext)
library(textrank)
library(rvest)
## Warning: package &#39;xml2&#39; was built under R version 3.6.2</code></pre>
<p>To showcase this method I have randomly (EXTENSIVELY filtered political and controversial) selected an article as our guinea pig. The main body is selected using the <code>html_nodes</code>.</p>
<pre class="r"><code>url &lt;- &quot;http://time.com/5196761/fitbit-ace-kids-fitness-tracker/&quot;
article &lt;- read_html(url) %&gt;%
  html_nodes(&#39;div[class=&quot;padded&quot;]&#39;) %&gt;%
  html_text()</code></pre>
<p>next we load the article into a <code>tibble</code> (since tidytext required the input as a data.frame). We start by tokenize according to sentences which is done by setting <code>token = "sentences"</code> in <code>unnest_tokens</code>. The tokenization is not always perfect using this tokenizer, but it have a low number of dependencies and is sufficient for this showcase. Lastly we add sentence number column and switch the order of the columns (<code>textrank_sentences</code> prefers the columns in a certain order).</p>
<pre class="r"><code>article_sentences &lt;- tibble(text = article) %&gt;%
  unnest_tokens(sentence, text, token = &quot;sentences&quot;) %&gt;%
  mutate(sentence_id = row_number()) %&gt;%
  select(sentence_id, sentence)</code></pre>
<p>next we will tokenize again but this time to get words. In doing this we will retain the <code>sentence_id</code> column in our data.</p>
<pre class="r"><code>article_words &lt;- article_sentences %&gt;%
  unnest_tokens(word, sentence)</code></pre>
<p>now we have all the sufficient input for the <code>textrank_sentences</code> function. However we will go one step further and remove the stop words in <code>article_words</code> since they would appear in most of the sentences and doesn’t really carry any information in them self.</p>
<pre class="r"><code>article_words &lt;- article_words %&gt;%
  anti_join(stop_words, by = &quot;word&quot;)</code></pre>
</div>
<div id="running-textrank" class="section level2">
<h2>Running TextRank</h2>
<p>Running the TextRank algorithm is easy, the <code>textrank_sentences</code> function only required 2 inputs.</p>
<ul>
<li>A data.frame with sentences</li>
<li>A data.frame with tokens (in our case words) which are part of the each sentence</li>
</ul>
<p>So we are ready to run</p>
<pre class="r"><code>article_summary &lt;- textrank_sentences(data = article_sentences, 
                                      terminology = article_words)</code></pre>
<p>The output have its own printing method that displays the top 5 sentences:</p>
<pre class="r"><code>article_summary
## Textrank on sentences, showing top 5 most important sentences found:
##   1. fitbit is launching a new fitness tracker designed for children called the fitbit ace, which will go on sale for $99.95 in the second quarter of this year.
##   2. fitbit says the tracker is designed for children eight years old and up.
##   3. sign up now                                                                                                                                                check the box if you do not wish to receive promotional offers via email from time.
##   4. the fitbit ace looks a lot like the company’s alta tracker, but with a few child-friendly tweaks.
##   5. like many of fitbit’s other products, the fitbit ace can automatically track steps, monitor active minutes, and remind kids to move when they’ve been still for too long.</code></pre>
<p>Which in itself is pretty good.</p>
</div>
<div id="digging-deeper" class="section level2">
<h2>Digging deeper</h2>
<p>While the printing method is good, we can extract the information to good some further analysis. The information about the sentences is stored in <code>sentences</code>. It includes the information <code>article_sentences</code> plus the calculated textrank score.</p>
<pre class="r"><code>article_summary[[&quot;sentences&quot;]]</code></pre>
<p>Lets begging by extracting the top 3 and bottom 3 sentences to see how they differ.</p>
<pre class="r"><code>article_summary[[&quot;sentences&quot;]] %&gt;%
  arrange(desc(textrank)) %&gt;% 
  slice(1:3) %&gt;%
  pull(sentence)
## [1] &quot;fitbit is launching a new fitness tracker designed for children called the fitbit ace, which will go on sale for $99.95 in the second quarter of this year.&quot;                                                                                   
## [2] &quot;fitbit says the tracker is designed for children eight years old and up.&quot;                                                                                                                                                                      
## [3] &quot;sign up now                                                                                                                                                check the box if you do not wish to receive promotional offers via email from time.&quot;</code></pre>
<p>As expected these are the same sentences as we saw earlier. However the button sentences, doesn’t include the word fitbit (properly rather important word) and focuses more “other” things, like the reference to another product in the second sentence.</p>
<pre class="r"><code>article_summary[[&quot;sentences&quot;]] %&gt;%
  arrange(textrank) %&gt;% 
  slice(1:3) %&gt;%
  pull(sentence)
## [1] &quot;contact us at editors@time.com.&quot;                                                                                                                                                                                                                                                                                                     
## [2] &quot;by signing up you are agreeing to our terms of use and privacy policy                                                                                                                                                                                                                                                     thank you!&quot;
## [3] &quot;the $39.99 nabi compete, meanwhile, is sold in pairs so that family members can work together to achieve movement milestones.&quot;</code></pre>
<p>If we look at the article over time, it would be interesting to see where the important sentences appear.</p>
<pre class="r"><code>article_summary[[&quot;sentences&quot;]] %&gt;%
  ggplot(aes(textrank_id, textrank, fill = textrank_id)) +
  geom_col() +
  theme_minimal() +
  scale_fill_viridis_c() +
  guides(fill = &quot;none&quot;) +
  labs(x = &quot;Sentence&quot;,
       y = &quot;TextRank score&quot;,
       title = &quot;4 Most informative sentences appear within first half of sentences&quot;,
       subtitle = &#39;In article &quot;Fitbits Newest Fitness Tracker Is Just for Kids&quot;&#39;,
       caption = &quot;Source: http://time.com/5196761/fitbit-ace-kids-fitness-tracker/&quot;)</code></pre>
<p><img src="/post/2018-03-15-tidy-text-summarization/index_files/figure-html/unnamed-chunk-11-1.png" width="700px" style="display: block; margin: auto;" /></p>
</div>
<div id="working-with-books" class="section level2">
<h2>Working with books???</h2>
<p>Summaries help cut down the reading when used on articles. Would the same approach work on books? Lets see what happens when you exchange “sentence” in “article” with “chapter” in “book”. I’ll go to my old friend <code>emma</code> form the <code>janeaustenr</code> package. We will borrow some code from the <a href="https://www.tidytextmining.com/tidytext.html">Text Mining with R</a> book to create the chapters. Remember that we want 1 chapter per row.</p>
<pre class="r"><code>emma_chapters &lt;- janeaustenr::emma %&gt;%
  tibble(text = .) %&gt;%
  mutate(chapter_id = cumsum(str_detect(text, regex(&quot;^chapter [\\divxlc]&quot;,
                                                 ignore_case = TRUE)))) %&gt;%
  filter(chapter_id &gt; 0) %&gt;%
  group_by(chapter_id) %&gt;%
  summarise(text = paste(text, collapse = &#39; &#39;))</code></pre>
<p>and proceed as before to find the words and remove the stop words.</p>
<pre class="r"><code>emma_words &lt;- emma_chapters %&gt;%
  unnest_tokens(word, text) %&gt;%
  anti_join(stop_words, by = &quot;word&quot;)</code></pre>
<p>We run the <code>textrank_sentences</code> function again. It should still be very quick, as the bottleneck of the algorithm is more with the number of vertices rather then their individual size.</p>
<pre class="r"><code>emma_summary &lt;- textrank_sentences(data = emma_chapters, 
                                   terminology = emma_words)</code></pre>
<p>We will be careful not to use the standard printing method as it would print 5 whole chapter!!</p>
<p>Instead we will look at the bar chart again to see if the important chapters appear in any particular order.</p>
<pre class="r"><code>emma_summary[[&quot;sentences&quot;]] %&gt;%
  ggplot(aes(textrank_id, textrank, fill = textrank_id)) +
  geom_col() +
  theme_minimal() +
  scale_fill_viridis_c(option = &quot;inferno&quot;) +
  guides(fill = &quot;none&quot;) +
  labs(x = &quot;Chapter&quot;,
       y = &quot;TextRank score&quot;,
       title = &quot;Chapter importance in the novel Emma by Jane Austen&quot;) +
  scale_x_continuous(breaks = seq(from = 0, to = 55, by = 5))</code></pre>
<p><img src="/post/2018-03-15-tidy-text-summarization/index_files/figure-html/unnamed-chunk-15-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>Which doesn’t appear to be the case in this particular text (which is properly good since skipping a chapter would be discouraged in a book like Emma). however it might prove helpful in non-chronological texts.</p>
<details closed>
<p><summary> <span title="Click to Expand"> session information </span> </summary></p>
<pre class="r"><code>
─ Session info ───────────────────────────────────────────────────────────────
 setting  value                       
 version  R version 3.6.0 (2019-04-26)
 os       macOS Mojave 10.14.6        
 system   x86_64, darwin15.6.0        
 ui       X11                         
 language (EN)                        
 collate  en_US.UTF-8                 
 ctype    en_US.UTF-8                 
 tz       America/Los_Angeles         
 date     2020-04-23                  

─ Packages ───────────────────────────────────────────────────────────────────
 ! package     * version date       lib source        
 P assertthat    0.2.1   2019-03-21 [?] CRAN (R 3.6.0)
 P backports     1.1.6   2020-04-05 [?] CRAN (R 3.6.0)
 P blogdown      0.18    2020-03-04 [?] CRAN (R 3.6.0)
 P bookdown      0.18    2020-03-05 [?] CRAN (R 3.6.0)
 P broom         0.5.5   2020-02-29 [?] CRAN (R 3.6.0)
 P cellranger    1.1.0   2016-07-27 [?] CRAN (R 3.6.0)
 P cli           2.0.2   2020-02-28 [?] CRAN (R 3.6.0)
 P clipr         0.7.0   2019-07-23 [?] CRAN (R 3.6.0)
 P colorspace    1.4-1   2019-03-18 [?] CRAN (R 3.6.0)
 P crayon        1.3.4   2017-09-16 [?] CRAN (R 3.6.0)
 P data.table    1.12.8  2019-12-09 [?] CRAN (R 3.6.0)
 P DBI           1.1.0   2019-12-15 [?] CRAN (R 3.6.0)
 P dbplyr        1.4.2   2019-06-17 [?] CRAN (R 3.6.0)
 P desc          1.2.0   2018-05-01 [?] CRAN (R 3.6.0)
 P details     * 0.2.1   2020-01-12 [?] CRAN (R 3.6.0)
 P digest        0.6.25  2020-02-23 [?] CRAN (R 3.6.0)
 P dplyr       * 0.8.5   2020-03-07 [?] CRAN (R 3.6.0)
 P ellipsis      0.3.0   2019-09-20 [?] CRAN (R 3.6.0)
 P evaluate      0.14    2019-05-28 [?] CRAN (R 3.6.0)
 P fansi         0.4.1   2020-01-08 [?] CRAN (R 3.6.0)
 P forcats     * 0.5.0   2020-03-01 [?] CRAN (R 3.6.0)
 P fs            1.4.1   2020-04-04 [?] CRAN (R 3.6.0)
 P generics      0.0.2   2018-11-29 [?] CRAN (R 3.6.0)
 P ggplot2     * 3.3.0   2020-03-05 [?] CRAN (R 3.6.0)
 P glue          1.4.0   2020-04-03 [?] CRAN (R 3.6.0)
 P gtable        0.3.0   2019-03-25 [?] CRAN (R 3.6.0)
 P haven         2.2.0   2019-11-08 [?] CRAN (R 3.6.0)
 P hms           0.5.3   2020-01-08 [?] CRAN (R 3.6.0)
 P htmltools     0.4.0   2019-10-04 [?] CRAN (R 3.6.0)
 P httr          1.4.1   2019-08-05 [?] CRAN (R 3.6.0)
 P igraph        1.2.5   2020-03-19 [?] CRAN (R 3.6.0)
 P janeaustenr   0.1.5   2017-06-10 [?] CRAN (R 3.6.0)
 P jsonlite      1.6.1   2020-02-02 [?] CRAN (R 3.6.0)
 P knitr       * 1.28    2020-02-06 [?] CRAN (R 3.6.0)
 P lattice       0.20-41 2020-04-02 [?] CRAN (R 3.6.0)
 P lifecycle     0.2.0   2020-03-06 [?] CRAN (R 3.6.0)
 P lubridate     1.7.8   2020-04-06 [?] CRAN (R 3.6.0)
 P magrittr      1.5     2014-11-22 [?] CRAN (R 3.6.0)
 P Matrix        1.2-18  2019-11-27 [?] CRAN (R 3.6.0)
 P modelr        0.1.6   2020-02-22 [?] CRAN (R 3.6.0)
 P munsell       0.5.0   2018-06-12 [?] CRAN (R 3.6.0)
 P nlme          3.1-145 2020-03-04 [?] CRAN (R 3.6.0)
 P pillar        1.4.3   2019-12-20 [?] CRAN (R 3.6.0)
 P pkgconfig     2.0.3   2019-09-22 [?] CRAN (R 3.6.0)
 P png           0.1-7   2013-12-03 [?] CRAN (R 3.6.0)
 P purrr       * 0.3.3   2019-10-18 [?] CRAN (R 3.6.0)
 P R6            2.4.1   2019-11-12 [?] CRAN (R 3.6.0)
 P Rcpp          1.0.4.6 2020-04-09 [?] CRAN (R 3.6.0)
 P readr       * 1.3.1   2018-12-21 [?] CRAN (R 3.6.0)
 P readxl        1.3.1   2019-03-13 [?] CRAN (R 3.6.0)
   renv          0.9.3   2020-02-10 [1] CRAN (R 3.6.0)
 P reprex        0.3.0   2019-05-16 [?] CRAN (R 3.6.0)
 P rlang         0.4.5   2020-03-01 [?] CRAN (R 3.6.0)
 P rmarkdown     2.1     2020-01-20 [?] CRAN (R 3.6.0)
 P rprojroot     1.3-2   2018-01-03 [?] CRAN (R 3.6.0)
 P rstudioapi    0.11    2020-02-07 [?] CRAN (R 3.6.0)
 P rvest       * 0.3.5   2019-11-08 [?] CRAN (R 3.6.0)
 P scales        1.1.0   2019-11-18 [?] CRAN (R 3.6.0)
 P sessioninfo   1.1.1   2018-11-05 [?] CRAN (R 3.6.0)
 P SnowballC     0.7.0   2020-04-01 [?] CRAN (R 3.6.2)
 P stringi       1.4.6   2020-02-17 [?] CRAN (R 3.6.0)
 P stringr     * 1.4.0   2019-02-10 [?] CRAN (R 3.6.0)
 P textrank    * 0.3.0   2019-01-17 [?] CRAN (R 3.6.0)
 P tibble      * 3.0.1   2020-04-20 [?] CRAN (R 3.6.2)
 P tidyr       * 1.0.2   2020-01-24 [?] CRAN (R 3.6.0)
 P tidyselect    1.0.0   2020-01-27 [?] CRAN (R 3.6.0)
 P tidytext    * 0.2.3   2020-03-04 [?] CRAN (R 3.6.0)
 P tidyverse   * 1.3.0   2019-11-21 [?] CRAN (R 3.6.0)
 P tokenizers    0.2.1   2018-03-29 [?] CRAN (R 3.6.0)
 P vctrs         0.2.4   2020-03-10 [?] CRAN (R 3.6.0)
 P withr         2.1.2   2018-03-15 [?] CRAN (R 3.6.0)
 P xfun          0.13    2020-04-13 [?] CRAN (R 3.6.2)
 P xml2        * 1.3.0   2020-04-01 [?] CRAN (R 3.6.2)
 P yaml          2.2.1   2020-02-01 [?] CRAN (R 3.6.0)

[1] /Users/emilhvitfeldthansen/Desktop/blogv4/renv/library/R-3.6/x86_64-apple-darwin15.6.0
[2] /private/var/folders/m0/zmxymdmd7ps0q_tbhx0d_26w0000gn/T/RtmpxWontu/renv-system-library

 P ── Loaded and on-disk path mismatch.
</code></pre>
</details>
<p><br></p>
</div>
