---
title: 'Textrecipes series 1: Term Frequency'
date: '2020-05-05'
slug: textrecipes-series-tf
categories: [tidymodels, textrecipes, textrecipes series, tidytuesday]
image:
  preview_only: true
---



<p>This is the first blog post in a series I am starting to go over the various text preprocessing workflows you can do with <a href="https://github.com/tidymodels/textrecipes">textrecipes</a>. In this post will we start simple with <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Term_frequency_2">term frequencies</a>.</p>
<p>Today we are lucky with timing to be able to use the current <a href="https://github.com/rfordatascience/tidytuesday">#tidytuesday</a> dataset about <a href="https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-05-05">Animal Crossing - New Horizons</a>.
There are a lot of different datasets available for us this week but we will only be looking at the user reviews.</p>
<div id="packages" class="section level2">
<h2>Packages üì¶</h2>
<p>We are going fairly light package wise this time only needing <a href="https://www.tidymodels.org/">tidymodels</a>, textrecipes, and lastly tidytext for EDA.</p>
<pre class="r"><code>library(tidymodels)
library(textrecipes)
library(tidytext)
theme_set(theme_minimal())</code></pre>
</div>
<div id="exploring-the-data" class="section level2">
<h2>Exploring the data ‚õè</h2>
<p>We start by reading in the data.
I want to set the goal of this modeling task to predict if a review is positive or not.
More specifically I (somehow arbitrarily) denote a review with a grade of 8 or higher to be a ‚ÄúHigh‚Äù review and everything else ‚ÄúLow‚Äù.
I split the data into a training and testing dataset right away before looking at the data.</p>
<pre class="r"><code>user_reviews &lt;- readr::read_tsv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/user_reviews.tsv&#39;)</code></pre>
<pre class="r"><code>user_reviews &lt;- user_reviews %&gt;%
  mutate(grade = factor(grade &gt; 7, c(TRUE, FALSE), c(&quot;High&quot;, &quot;Low&quot;)))

set.seed(1234)
review_split &lt;- initial_split(user_reviews)

review_training &lt;- training(review_split)
review_testing &lt;- training(review_split)</code></pre>
<p>Taking a <code>glimpse()</code> of the data reveals 4 variables.
<code>grade</code> is a factor with the two levels ‚ÄúHigh‚Äù and ‚ÄúLow‚Äù.
This is what we are trying to predict.
Next, we have <code>user_name</code> which we won‚Äôt be using for this analysis, <code>text</code> is the most important variable as it contains the reviews. We also get a <code>date</code> variable denoting the date the review was submitted.</p>
<pre class="r"><code>glimpse(review_training)
## Rows: 2,250
## Columns: 4
## $ grade     &lt;fct&gt; Low, Low, Low, Low, Low, Low, Low, Low, Low, Low, Low, Low,‚Ä¶
## $ user_name &lt;chr&gt; &quot;mds27272&quot;, &quot;lolo2178&quot;, &quot;Roachant&quot;, &quot;Houndf&quot;, &quot;ProfessorFox‚Ä¶
## $ text      &lt;chr&gt; &quot;My gf started playing before me. No option to create my ow‚Ä¶
## $ date      &lt;date&gt; 2020-03-20, 2020-03-20, 2020-03-20, 2020-03-20, 2020-03-20‚Ä¶</code></pre>
<p>We First look at the distribution of ‚ÄúHigh‚Äù and ‚ÄúLow‚Äù scoring reviews.</p>
<pre class="r"><code>review_training %&gt;%
  ggplot(aes(grade)) +
  geom_bar()</code></pre>
<p><img src="/post/2020-05-05-textrecipes-series-tf/index_files/figure-html/unnamed-chunk-5-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>it is slightly skewed but we will soldier on and ignore it. Next, let us take a look at the distribution of the dates.
Remember that the game release on March 20th of this year, so we can plot the distribution of days since release.
This provides us with an upper bound of how many days they have access to the game before leaving the review.</p>
<pre class="r"><code>review_training %&gt;%
  transmute(date = as.numeric(date - as.Date(&quot;2020-03-20&quot;))) %&gt;%
  ggplot(aes(date)) +
  geom_bar() +
  labs(title = &quot;Number of days since release&quot;)</code></pre>
<p><img src="/post/2020-05-05-textrecipes-series-tf/index_files/figure-html/unnamed-chunk-6-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>We see a spike on the 1st day as well as the 5th.
This is a little worrisome considering Animal Crossing games tend to be played casually over a long period of time and are tend to be slow and <a href="https://howlongtobeat.com/game.php?id=474">take a long time to beat</a>.</p>
<p>Lastly, let us get ourselves some summary stats of the text itself.</p>
<pre class="r"><code>review_tokens &lt;- review_training %&gt;%
  unnest_tokens(tokens, text)</code></pre>
<p>We can look at the distribution of the number of tokens in the reviews</p>
<pre class="r"><code>review_tokens %&gt;%
  count(user_name) %&gt;%
  ggplot(aes(n)) +
  geom_histogram(binwidth = 10) +
  geom_vline(xintercept = 100, color = &quot;firebrick&quot;) +
  annotate(&quot;text&quot;, x = 105, y = 205, hjust = 0, color = &quot;firebrick&quot;,
           label = &quot;Sharp clif between reviews with less and more then 100 word&quot;) +
  labs(title = &quot;Distribution of number of words in user reviews&quot;)</code></pre>
<p><img src="/post/2020-05-05-textrecipes-series-tf/index_files/figure-html/unnamed-chunk-8-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>This is a highly <a href="https://en.wikipedia.org/wiki/Multimodal_distribution">bimodal distribution</a>.
This is something we should include in our model.
But we are sadly too early in our <em>textrecipes series</em> to address this kind of preprocessing, in a later post will we take a look at <a href="https://tidymodels.github.io/textrecipes/reference/step_textfeature.html">step_textfeature()</a> that can do that.</p>
</div>
<div id="modeling-Ô∏è" class="section level2">
<h2>Modeling ‚öôÔ∏è</h2>
<p>In the preprocessing, we are including both the <code>date</code> and <code>text</code> variable.
There are many different things we could with the data variable.
I‚Äôll go simple and calculate the difference in time between the release day and the date the review was submitted.
For the text we will again go simple, I‚Äôll start by tokenizing to words with the default <em>tokenizers</em> engine.
Next, we will remove stopwords, being conservative to only use the snowball stopword list which removes the least amount of words.
Let us take a look at the words we are trying to remove to verify they ate appropriate.</p>
<pre class="r"><code>stopwords::data_stopwords_snowball$en
##   [1] &quot;i&quot;          &quot;me&quot;         &quot;my&quot;         &quot;myself&quot;     &quot;we&quot;        
##   [6] &quot;our&quot;        &quot;ours&quot;       &quot;ourselves&quot;  &quot;you&quot;        &quot;your&quot;      
##  [11] &quot;yours&quot;      &quot;yourself&quot;   &quot;yourselves&quot; &quot;he&quot;         &quot;him&quot;       
##  [16] &quot;his&quot;        &quot;himself&quot;    &quot;she&quot;        &quot;her&quot;        &quot;hers&quot;      
##  [21] &quot;herself&quot;    &quot;it&quot;         &quot;its&quot;        &quot;itself&quot;     &quot;they&quot;      
##  [26] &quot;them&quot;       &quot;their&quot;      &quot;theirs&quot;     &quot;themselves&quot; &quot;what&quot;      
##  [31] &quot;which&quot;      &quot;who&quot;        &quot;whom&quot;       &quot;this&quot;       &quot;that&quot;      
##  [36] &quot;these&quot;      &quot;those&quot;      &quot;am&quot;         &quot;is&quot;         &quot;are&quot;       
##  [41] &quot;was&quot;        &quot;were&quot;       &quot;be&quot;         &quot;been&quot;       &quot;being&quot;     
##  [46] &quot;have&quot;       &quot;has&quot;        &quot;had&quot;        &quot;having&quot;     &quot;do&quot;        
##  [51] &quot;does&quot;       &quot;did&quot;        &quot;doing&quot;      &quot;would&quot;      &quot;should&quot;    
##  [56] &quot;could&quot;      &quot;ought&quot;      &quot;i&#39;m&quot;        &quot;you&#39;re&quot;     &quot;he&#39;s&quot;      
##  [61] &quot;she&#39;s&quot;      &quot;it&#39;s&quot;       &quot;we&#39;re&quot;      &quot;they&#39;re&quot;    &quot;i&#39;ve&quot;      
##  [66] &quot;you&#39;ve&quot;     &quot;we&#39;ve&quot;      &quot;they&#39;ve&quot;    &quot;i&#39;d&quot;        &quot;you&#39;d&quot;     
##  [71] &quot;he&#39;d&quot;       &quot;she&#39;d&quot;      &quot;we&#39;d&quot;       &quot;they&#39;d&quot;     &quot;i&#39;ll&quot;      
##  [76] &quot;you&#39;ll&quot;     &quot;he&#39;ll&quot;      &quot;she&#39;ll&quot;     &quot;we&#39;ll&quot;      &quot;they&#39;ll&quot;   
##  [81] &quot;isn&#39;t&quot;      &quot;aren&#39;t&quot;     &quot;wasn&#39;t&quot;     &quot;weren&#39;t&quot;    &quot;hasn&#39;t&quot;    
##  [86] &quot;haven&#39;t&quot;    &quot;hadn&#39;t&quot;     &quot;doesn&#39;t&quot;    &quot;don&#39;t&quot;      &quot;didn&#39;t&quot;    
##  [91] &quot;won&#39;t&quot;      &quot;wouldn&#39;t&quot;   &quot;shan&#39;t&quot;     &quot;shouldn&#39;t&quot;  &quot;can&#39;t&quot;     
##  [96] &quot;cannot&quot;     &quot;couldn&#39;t&quot;   &quot;mustn&#39;t&quot;    &quot;let&#39;s&quot;      &quot;that&#39;s&quot;    
## [101] &quot;who&#39;s&quot;      &quot;what&#39;s&quot;     &quot;here&#39;s&quot;     &quot;there&#39;s&quot;    &quot;when&#39;s&quot;    
## [106] &quot;where&#39;s&quot;    &quot;why&#39;s&quot;      &quot;how&#39;s&quot;      &quot;a&quot;          &quot;an&quot;        
## [111] &quot;the&quot;        &quot;and&quot;        &quot;but&quot;        &quot;if&quot;         &quot;or&quot;        
## [116] &quot;because&quot;    &quot;as&quot;         &quot;until&quot;      &quot;while&quot;      &quot;of&quot;        
## [121] &quot;at&quot;         &quot;by&quot;         &quot;for&quot;        &quot;with&quot;       &quot;about&quot;     
## [126] &quot;against&quot;    &quot;between&quot;    &quot;into&quot;       &quot;through&quot;    &quot;during&quot;    
## [131] &quot;before&quot;     &quot;after&quot;      &quot;above&quot;      &quot;below&quot;      &quot;to&quot;        
## [136] &quot;from&quot;       &quot;up&quot;         &quot;down&quot;       &quot;in&quot;         &quot;out&quot;       
## [141] &quot;on&quot;         &quot;off&quot;        &quot;over&quot;       &quot;under&quot;      &quot;again&quot;     
## [146] &quot;further&quot;    &quot;then&quot;       &quot;once&quot;       &quot;here&quot;       &quot;there&quot;     
## [151] &quot;when&quot;       &quot;where&quot;      &quot;why&quot;        &quot;how&quot;        &quot;all&quot;       
## [156] &quot;any&quot;        &quot;both&quot;       &quot;each&quot;       &quot;few&quot;        &quot;more&quot;      
## [161] &quot;most&quot;       &quot;other&quot;      &quot;some&quot;       &quot;such&quot;       &quot;no&quot;        
## [166] &quot;nor&quot;        &quot;not&quot;        &quot;only&quot;       &quot;own&quot;        &quot;same&quot;      
## [171] &quot;so&quot;         &quot;than&quot;       &quot;too&quot;        &quot;very&quot;       &quot;will&quot;</code></pre>
<p>The list contains a good amount of pronouns and negations, but considering the subject matter, I don‚Äôt think it will introduce much bias.
We will apply a <code>step_tokenfilter()</code> to filter the tokens we keep based on frequency.
We use <code>tune()</code> to indicate that we want to do hyperparameter tuning to determine the optimal number of tokens to keep.
We end our recipe with <code>step_tf()</code> to calculate term frequencies from the tokens we kept.</p>
<pre class="r"><code>rec_spec &lt;- recipe(grade ~ text + date, review_training) %&gt;%
  # Days since release
  step_mutate(date = as.numeric(date - as.Date(&quot;2020-03-20&quot;))) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  step_tokenfilter(text, max_tokens = tune()) %&gt;%
  # Calculate term frequencies
  step_tf(text, weight_scheme = &quot;binary&quot;)</code></pre>
<p><code>step_tf()</code> has one main argument <code>weight_scheme</code> which determines how the term frequencies should be represented. I will be using ‚Äúbinary‚Äù This will return a 1 if the word is present in the review an 0. This is a kind of scaling since we are assuming that having the word ‚Äúgood‚Äù in the document once is providing as much evidence as if it appeared 10 times.
See <a href="https://tidymodels.github.io/textrecipes/reference/step_tf.html">?step_tf()</a> for more detail and other options.</p>
<p>The modeling will be using a radial basis function support vector machines (SVM).</p>
<pre class="r"><code>mod_spec &lt;- svm_rbf(cost = tune(), rbf_sigma = tune()) %&gt;%
  set_engine(&quot;kernlab&quot;) %&gt;%
  set_mode(&quot;classification&quot;)</code></pre>
<p>We will be tuning both the <code>cost</code> and <code>rbf_sigma</code> arguments.</p>
<p>To calculate the performance over the hyperparameter space will we do some V-fold Cross-Validation on our data.</p>
<pre class="r"><code>set.seed(1234)
review_folds &lt;- vfold_cv(review_training, v = 5)</code></pre>
<p>Now we are pretty much ready to run our model. We combine our model specification with the recipe specification to create a workflow object. This way we can tune the recipe and model jointly.</p>
<pre class="r"><code>review_wf &lt;- workflow() %&gt;%
  add_recipe(rec_spec) %&gt;%
  add_model(mod_spec)</code></pre>
<p>With everything in place will we go to <code>tune_grid()</code> to perform the model tuning via a grid search.</p>
<div class="note">
<p>I like to set <code>control = control_grid(verbose = TRUE)</code> to be able to see hard far along the grid search is going.</p>
</div>
<pre class="r"><code>tune_res &lt;- tune_grid(
  review_wf,
  resamples = review_folds,
  grid = 25,
  control = control_grid(verbose = TRUE)
)</code></pre>
<p>Now that we have the rune results we can find the best candidates we can simply use <code>show_best()</code></p>
<pre class="r"><code>show_best(tune_res, &quot;accuracy&quot;)
## # A tibble: 5 x 8
##      cost rbf_sigma max_tokens .metric  .estimator  mean     n std_err
##     &lt;dbl&gt;     &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1  1.31    0.000382        876 accuracy binary     0.891     5 0.00337
## 2  2.75    0.000164        314 accuracy binary     0.864     5 0.00575
## 3  0.286   0.00113         193 accuracy binary     0.838     5 0.00504
## 4 24.3     0.109           620 accuracy binary     0.642     5 0.00897
## 5  0.0918  0.00185         736 accuracy binary     0.641     5 0.00879</code></pre>
<p>We notice that the top candidates have very similar <code>.estimator</code>s but the 3 parameters vary quite a bit. Lets do a little vizualizations to see what is happening:</p>
<pre class="r"><code>collect_metrics(tune_res) %&gt;%
  filter(.metric == &quot;accuracy&quot;) %&gt;%
  ggplot(aes(cost, rbf_sigma, size = max_tokens, color = mean)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10() +
  scale_color_viridis_c()</code></pre>
<p><img src="/post/2020-05-05-textrecipes-series-tf/index_files/figure-html/unnamed-chunk-16-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>when we are evaluating the accuracy it seems that a combination of high <code>rbf_sigma</code> and high <code>cost</code> yields to high accuracy.</p>
<p>When we are evaluating the roc_auc then it appears that both <code>max_tokens</code> and <code>cost</code> don‚Äôt have too much influence and a high value of <code>rbf_sigma</code> is really bad.</p>
<pre class="r"><code>collect_metrics(tune_res) %&gt;%
  filter(.metric == &quot;roc_auc&quot;) %&gt;%
  ggplot(aes(cost, rbf_sigma, size = max_tokens, color = mean)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10() +
  scale_color_viridis_c()</code></pre>
<p><img src="/post/2020-05-05-textrecipes-series-tf/index_files/figure-html/unnamed-chunk-17-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>I‚Äôll select a model with the highest accuracy in this use-case.
We can do that with the <code>select_best()</code> function.
Then we can use the <code>finalize_workflow()</code> function to update our workflow with the new hyperparameters.</p>
<pre class="r"><code>best_accuracy &lt;- select_best(tune_res, &quot;accuracy&quot;)

final_wf &lt;- finalize_workflow(
  review_wf,
  best_accuracy
)

final_wf
## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Recipe
## Model: svm_rbf()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 5 Recipe Steps
## 
## ‚óè step_mutate()
## ‚óè step_tokenize()
## ‚óè step_stopwords()
## ‚óè step_tokenfilter()
## ‚óè step_tf()
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## Radial Basis Function Support Vector Machine Specification (classification)
## 
## Main Arguments:
##   cost = 1.31257376115796
##   rbf_sigma = 0.000382104630228968
## 
## Computational engine: kernlab</code></pre>
<p>lastly, we will do a list fit and see how well the final model did on our testing data:</p>
<pre class="r"><code>final_res &lt;- final_wf %&gt;%
  last_fit(review_split)

final_res %&gt;%
  collect_metrics()
## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.869
## 2 roc_auc  binary         0.935</code></pre>
<p>We did decently well on both accounts.</p>
<details closed>
<p><summary> <span title="Click to Expand"> session information </span> </summary></p>
<pre class="r"><code>
‚îÄ Session info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
 setting  value                       
 version  R version 3.6.0 (2019-04-26)
 os       macOS Mojave 10.14.6        
 system   x86_64, darwin15.6.0        
 ui       X11                         
 language (EN)                        
 collate  en_US.UTF-8                 
 ctype    en_US.UTF-8                 
 tz       America/Los_Angeles         
 date     2020-05-05                  

‚îÄ Packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
 ! package       * version    date       lib source                            
 P assertthat      0.2.1      2019-03-21 [?] CRAN (R 3.6.0)                    
 P backports       1.1.6      2020-04-05 [?] CRAN (R 3.6.0)                    
 P base64enc       0.1-3      2015-07-28 [?] CRAN (R 3.6.0)                    
 P bayesplot       1.7.1      2019-12-01 [?] CRAN (R 3.6.0)                    
 P blogdown        0.18       2020-03-04 [?] CRAN (R 3.6.0)                    
 P bookdown        0.18       2020-03-05 [?] CRAN (R 3.6.0)                    
 P boot            1.3-24     2019-12-20 [?] CRAN (R 3.6.0)                    
 P broom         * 0.5.6      2020-04-20 [?] CRAN (R 3.6.2)                    
 P callr           3.4.3      2020-03-28 [?] CRAN (R 3.6.2)                    
 P class           7.3-16     2020-03-25 [?] CRAN (R 3.6.0)                    
 P cli             2.0.2      2020-02-28 [?] CRAN (R 3.6.0)                    
 P clipr           0.7.0      2019-07-23 [?] CRAN (R 3.6.0)                    
 P codetools       0.2-16     2018-12-24 [?] CRAN (R 3.6.0)                    
 P colorspace      1.4-1      2019-03-18 [?] CRAN (R 3.6.0)                    
 P colourpicker    1.0        2017-09-27 [?] CRAN (R 3.6.0)                    
   crayon          1.3.4      2017-09-16 [1] CRAN (R 3.6.0)                    
 P crosstalk       1.1.0.1    2020-03-13 [?] CRAN (R 3.6.0)                    
 P curl            4.3        2019-12-02 [?] CRAN (R 3.6.0)                    
 P desc            1.2.0      2018-05-01 [?] CRAN (R 3.6.0)                    
 P details       * 0.2.1      2020-01-12 [?] CRAN (R 3.6.0)                    
 P dials         * 0.0.6      2020-04-03 [?] CRAN (R 3.6.0)                    
 P DiceDesign      1.8-1      2019-07-31 [?] CRAN (R 3.6.0)                    
 P digest          0.6.25     2020-02-23 [?] CRAN (R 3.6.0)                    
 P dplyr         * 0.8.5      2020-03-07 [?] CRAN (R 3.6.0)                    
 P DT              0.13       2020-03-23 [?] CRAN (R 3.6.0)                    
 P dygraphs        1.1.1.6    2018-07-11 [?] CRAN (R 3.6.0)                    
 P ellipsis        0.3.0      2019-09-20 [?] CRAN (R 3.6.0)                    
   emo             0.0.0.9000 2020-05-05 [1] Github (Hadley/emo@3f03b11)       
 P evaluate        0.14       2019-05-28 [?] CRAN (R 3.6.0)                    
 P fansi           0.4.1      2020-01-08 [?] CRAN (R 3.6.0)                    
 P farver          2.0.3      2020-01-16 [?] CRAN (R 3.6.0)                    
 P fastmap         1.0.1      2019-10-08 [?] CRAN (R 3.6.0)                    
 P foreach         1.5.0      2020-03-30 [?] CRAN (R 3.6.2)                    
 P fs              1.4.1      2020-04-04 [?] CRAN (R 3.6.0)                    
 P furrr           0.1.0      2018-05-16 [?] CRAN (R 3.6.0)                    
 P future          1.17.0     2020-04-18 [?] CRAN (R 3.6.2)                    
 P generics        0.0.2      2018-11-29 [?] CRAN (R 3.6.0)                    
 P ggplot2       * 3.3.0      2020-03-05 [?] CRAN (R 3.6.0)                    
 P ggridges        0.5.2      2020-01-12 [?] CRAN (R 3.6.0)                    
 P globals         0.12.5     2019-12-07 [?] CRAN (R 3.6.0)                    
 P glue            1.4.0      2020-04-03 [?] CRAN (R 3.6.0)                    
 P gower           0.2.1      2019-05-14 [?] CRAN (R 3.6.0)                    
 P GPfit           1.0-8      2019-02-08 [?] CRAN (R 3.6.0)                    
 P gridExtra       2.3        2017-09-09 [?] CRAN (R 3.6.0)                    
 P gtable          0.3.0      2019-03-25 [?] CRAN (R 3.6.0)                    
 P gtools          3.8.2      2020-03-31 [?] CRAN (R 3.6.2)                    
 P hardhat         0.1.2      2020-02-28 [?] CRAN (R 3.6.0)                    
 P hms             0.5.3      2020-01-08 [?] CRAN (R 3.6.0)                    
 P htmltools       0.4.0      2019-10-04 [?] CRAN (R 3.6.0)                    
 P htmlwidgets     1.5.1      2019-10-08 [?] CRAN (R 3.6.0)                    
 P httpuv          1.5.2      2019-09-11 [?] CRAN (R 3.6.0)                    
 P httr            1.4.1      2019-08-05 [?] CRAN (R 3.6.0)                    
 P igraph          1.2.5      2020-03-19 [?] CRAN (R 3.6.0)                    
 P infer         * 0.5.1      2019-11-19 [?] CRAN (R 3.6.0)                    
 P inline          0.3.15     2018-05-18 [?] CRAN (R 3.6.0)                    
 P ipred           0.9-9      2019-04-28 [?] CRAN (R 3.6.0)                    
 P iterators       1.0.12     2019-07-26 [?] CRAN (R 3.6.0)                    
 P janeaustenr     0.1.5      2017-06-10 [?] CRAN (R 3.6.0)                    
 P kernlab         0.9-29     2019-11-12 [?] CRAN (R 3.6.0)                    
 P knitr         * 1.28       2020-02-06 [?] CRAN (R 3.6.0)                    
 P labeling        0.3        2014-08-23 [?] CRAN (R 3.6.0)                    
 P later           1.0.0      2019-10-04 [?] CRAN (R 3.6.0)                    
 P lattice         0.20-41    2020-04-02 [?] CRAN (R 3.6.0)                    
 P lava            1.6.7      2020-03-05 [?] CRAN (R 3.6.0)                    
 P lhs             1.0.2      2020-04-13 [?] CRAN (R 3.6.2)                    
 P lifecycle       0.2.0      2020-03-09 [?] Github (r-lib/lifecycle@1b13d96)  
 P listenv         0.8.0      2019-12-05 [?] CRAN (R 3.6.0)                    
 P lme4            1.1-23     2020-04-07 [?] CRAN (R 3.6.0)                    
 P loo             2.2.0      2019-12-19 [?] CRAN (R 3.6.0)                    
 P lubridate       1.7.8      2020-04-06 [?] CRAN (R 3.6.0)                    
 P magrittr        1.5        2014-11-22 [?] CRAN (R 3.6.0)                    
 P markdown        1.1        2019-08-07 [?] CRAN (R 3.6.0)                    
 P MASS            7.3-51.5   2019-12-20 [?] CRAN (R 3.6.0)                    
 P Matrix          1.2-18     2019-11-27 [?] CRAN (R 3.6.0)                    
 P matrixStats     0.56.0     2020-03-13 [?] CRAN (R 3.6.0)                    
 P mime            0.9        2020-02-04 [?] CRAN (R 3.6.0)                    
   miniUI          0.1.1.1    2018-05-18 [1] CRAN (R 3.6.0)                    
 P minqa           1.2.4      2014-10-09 [?] CRAN (R 3.6.0)                    
 P munsell         0.5.0      2018-06-12 [?] CRAN (R 3.6.0)                    
 P nlme            3.1-145    2020-03-04 [?] CRAN (R 3.6.0)                    
 P nloptr          1.2.2.1    2020-03-11 [?] CRAN (R 3.6.0)                    
 P nnet            7.3-13     2020-02-25 [?] CRAN (R 3.6.0)                    
 P parsnip       * 0.1.0      2020-04-09 [?] CRAN (R 3.6.2)                    
 P pillar          1.4.3      2019-12-20 [?] CRAN (R 3.6.0)                    
 P pkgbuild        1.0.7      2020-04-25 [?] CRAN (R 3.6.2)                    
 P pkgconfig       2.0.3      2019-09-22 [?] CRAN (R 3.6.0)                    
 P plyr            1.8.6      2020-03-03 [?] CRAN (R 3.6.0)                    
 P png             0.1-7      2013-12-03 [?] CRAN (R 3.6.0)                    
 P prettyunits     1.1.1      2020-01-24 [?] CRAN (R 3.6.0)                    
 P pROC            1.16.2     2020-03-19 [?] CRAN (R 3.6.0)                    
 P processx        3.4.2      2020-02-09 [?] CRAN (R 3.6.0)                    
 P prodlim         2019.11.13 2019-11-17 [?] CRAN (R 3.6.0)                    
 P promises        1.1.0      2019-10-04 [?] CRAN (R 3.6.0)                    
 P ps              1.3.2      2020-02-13 [?] CRAN (R 3.6.0)                    
 P purrr         * 0.3.4      2020-04-17 [?] CRAN (R 3.6.2)                    
 P R6              2.4.1      2019-11-12 [?] CRAN (R 3.6.0)                    
 P Rcpp            1.0.4.6    2020-04-09 [?] CRAN (R 3.6.0)                    
 P readr           1.3.1      2018-12-21 [?] CRAN (R 3.6.0)                    
 P recipes       * 0.1.12     2020-05-01 [?] CRAN (R 3.6.2)                    
   renv            0.9.3      2020-02-10 [1] CRAN (R 3.6.0)                    
 P reshape2        1.4.4      2020-04-09 [?] CRAN (R 3.6.2)                    
 P rlang           0.4.6      2020-05-02 [?] CRAN (R 3.6.2)                    
 P rmarkdown       2.1        2020-01-20 [?] CRAN (R 3.6.0)                    
 P rpart           4.1-15     2019-04-12 [?] CRAN (R 3.6.0)                    
 P rprojroot       1.3-2      2018-01-03 [?] CRAN (R 3.6.0)                    
 P rsample       * 0.0.6      2020-03-31 [?] CRAN (R 3.6.2)                    
 P rsconnect       0.8.16     2019-12-13 [?] CRAN (R 3.6.0)                    
 P rstan           2.19.3     2020-02-11 [?] CRAN (R 3.6.0)                    
 P rstanarm        2.19.3     2020-02-11 [?] CRAN (R 3.6.0)                    
 P rstantools      2.0.0      2019-09-15 [?] CRAN (R 3.6.0)                    
   rstudioapi      0.11       2020-02-07 [1] CRAN (R 3.6.0)                    
 P scales        * 1.1.0      2019-11-18 [?] CRAN (R 3.6.0)                    
 P sessioninfo     1.1.1      2018-11-05 [?] CRAN (R 3.6.0)                    
   shiny           1.4.0.2    2020-03-13 [1] CRAN (R 3.6.0)                    
 P shinyjs         1.1        2020-01-13 [?] CRAN (R 3.6.0)                    
 P shinystan       2.5.0      2018-05-01 [?] CRAN (R 3.6.0)                    
 P shinythemes     1.1.2      2018-11-06 [?] CRAN (R 3.6.0)                    
 P SnowballC       0.7.0      2020-04-01 [?] CRAN (R 3.6.2)                    
 P StanHeaders     2.21.0-1   2020-01-19 [?] CRAN (R 3.6.0)                    
 P statmod         1.4.34     2020-02-17 [?] CRAN (R 3.6.0)                    
 P stopwords       2.0        2020-04-14 [?] CRAN (R 3.6.2)                    
 P stringi         1.4.6      2020-02-17 [?] CRAN (R 3.6.0)                    
 P stringr         1.4.0      2019-02-10 [?] CRAN (R 3.6.0)                    
 P survival        3.1-12     2020-03-28 [?] Github (therneau/survival@c55af18)
 P textrecipes   * 0.2.1      2020-05-04 [?] CRAN (R 3.6.0)                    
 P threejs         0.3.3      2020-01-21 [?] CRAN (R 3.6.0)                    
 P tibble        * 3.0.1      2020-04-20 [?] CRAN (R 3.6.2)                    
 P tidymodels    * 0.1.0      2020-02-16 [?] CRAN (R 3.6.0)                    
 P tidyposterior   0.0.2      2018-11-15 [?] CRAN (R 3.6.0)                    
 P tidypredict     0.4.5      2020-02-10 [?] CRAN (R 3.6.0)                    
 P tidyr           1.0.2      2020-01-24 [?] CRAN (R 3.6.0)                    
 P tidyselect      1.0.0      2020-01-27 [?] CRAN (R 3.6.0)                    
 P tidytext      * 0.2.4      2020-04-17 [?] CRAN (R 3.6.2)                    
 P timeDate        3043.102   2018-02-21 [?] CRAN (R 3.6.0)                    
 P tokenizers      0.2.1      2018-03-29 [?] CRAN (R 3.6.0)                    
 P tune          * 0.1.0      2020-04-02 [?] CRAN (R 3.6.0)                    
 P usethis         1.6.1      2020-04-29 [?] CRAN (R 3.6.2)                    
 P utf8            1.1.4      2018-05-24 [?] CRAN (R 3.6.0)                    
 P vctrs           0.2.4      2020-03-10 [?] CRAN (R 3.6.0)                    
 P viridisLite     0.3.0      2018-02-01 [?] CRAN (R 3.6.0)                    
 P withr           2.2.0      2020-04-20 [?] CRAN (R 3.6.2)                    
 P workflows     * 0.1.1      2020-03-17 [?] CRAN (R 3.6.0)                    
 P xfun            0.13       2020-04-13 [?] CRAN (R 3.6.2)                    
 P xml2            1.3.2      2020-04-23 [?] CRAN (R 3.6.2)                    
   xtable          1.8-4      2019-04-21 [1] CRAN (R 3.6.0)                    
 P xts             0.12-0     2020-01-19 [?] CRAN (R 3.6.0)                    
 P yaml            2.2.1      2020-02-01 [?] CRAN (R 3.6.0)                    
 P yardstick     * 0.0.6      2020-03-17 [?] CRAN (R 3.6.0)                    
 P zoo             1.8-8      2020-05-02 [?] CRAN (R 3.6.2)                    

[1] /Users/emilhvitfeldthansen/Github/hvitfeldt.me/renv/library/R-3.6/x86_64-apple-darwin15.6.0
[2] /private/var/folders/m0/zmxymdmd7ps0q_tbhx0d_26w0000gn/T/RtmpTCz51a/renv-system-library

 P ‚îÄ‚îÄ Loaded and on-disk path mismatch.
</code></pre>
</details>
<p><br></p>
</div>
