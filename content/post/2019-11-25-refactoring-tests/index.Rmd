---
title: Refactoring Tests
date: '2019-11-25'
categories: []
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(
  echo = TRUE,
  cache = TRUE,
  fig.width = 7, 
  fig.align = 'center',
  fig.asp = 0.618, # 1 / phi
  out.width = "700px")
knit_hooks$set(optipng = hook_optipng)
opts_chunk$set("optipng" = "-o5")
```

We all know the saying 

> When youâ€™ve written the same code 3 times, write a function

However, I would like to expend that to

> When you're written the same test 3 times, write a test function

During my lasting packages such as [prismatic](https://github.com/EmilHvitfeldt/prismatic),
I found myself copy-pasting tests around whenever I needed to test a new function.
I realized that the refactoring practices I try to apply in my general code writing,
wasn't carried over to the way I was writing my tests. 
I would frequency copy-paste hundreds of lines of tests only to replace the function name.
In this post will I go over a refactoring scenario I am working on at the moment. 

# The copy-pasted test

The **prismatic** package includes almost a dozen different functions that work mostly the same way.
They all take the same type of arguments, return the returns in the same fashion and so on.
This leads me to have a great overlap between what tests I'm performing for each function.

Taking a look at the following code chuck we see a test that makes sure that the function `clr_alpha()` complain when given the wrong type of the first argument.

```{r, eval=FALSE}
test_that("complain when `col` type is wrong.", {
  expect_error(clr_alpha("not a color"))

  expect_error(clr_alpha(list(pal = "#000000")))

  expect_error(clr_alpha(character()))
})
```

When looking at the same test for `clr_mix()` we see that it is a carbon copy except for the function name.

```{r, eval=FALSE}
test_that("it complains when col type is wrong.", {
  expect_error(clr_mix("not a color"))

  expect_error(clr_mix(list(pal = "#000000")))

  expect_error(clr_mix(character()))
})
```

I'm going to propose 2 different styles of refactoring, 
with the main difference being how RStudio returns the error when tests are not met.

## Fix #1 - Plays well with error messages

The first solution is to wrap the inside of your test into a function.
The above test would create the refactored testing-function

```{r}
test_wrong_input <- function(clr_) {
  expect_error(clr_("not a color"))

  expect_error(clr_(list(pal = "#000000")))

  expect_error(clr_(character()))
}
```

and the test would be changed to

```{r, eval=FALSE}
test_that("it complains when col type is wrong.", {
  test_wrong_input(clr_alpha)
})
```

this change will perform the tests,
and adding tests for the new function would only need 1 change in the test instead of 3.

```{r, eval=FALSE}
test_that("it complains when col type is wrong.", {
  test_wrong_input(clr_mix)
})
```

More importantly, let's imagine that we want to extend the types of wrong inputs we what to screen.
Now we simply just need to add it once and it propagates to all the functions.

The main benefit of this refactoring style is that when an error appears,
It will denote the line where the test broke.

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics("style1-error.png")
```

## Fix #2 - Less typing, worse error message

The second solution is to wrap the entire testing statement inside a function.
For this example, the function would look like this

```{r}
test_wrong_input <- function(clr_) {
  test_that("it complains when col type is wrong.", {
  expect_error(clr_("not a color"))

  expect_error(clr_(list(pal = "#000000")))

  expect_error(clr_(character()))
  })
}
```

and the testing would look like

```{r, eval=FALSE}
test_wrong_input(clr_mix)
```

This reduces the number of lines needed for each test from 3 down to 1.
However, it comes with a downside. 
When an error appears **testthat** will give the location of the definition of the test-function,
not the location from where it was called.

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics("style2-error.png")
```
We can still see that the error happens inside the "alpha" Context,
but it is slightly harder to track down.

## Fix #2.1 - ugly hack to give me the location

The second solution can be made slightly better by making the description of the test more informative.

```{r}
test_wrong_input <- function(clr_) {
  test_that(paste0("test_wrong_input: ",
                   deparse(substitute(clr_)),
                   "() complains when col type is wrong."), {
  expect_error(clr_("not a color"))

  expect_error(clr_(list(pal = "#000000")))

  expect_error(clr_("pink"))
  })
}
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics("style2.5-error.png")
```

It takes more work upfront when writing the test functions.
But it gives a compromise between the brevity of test files and the clarity of the debugging page.

Thanks for reading along! I hope you found it useful!
